{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1a2d421",
   "metadata": {},
   "source": [
    "# Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e69a5f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import optuna\n",
    "import mlflow\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision import transforms, models, datasets\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82abc2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7852cd20",
   "metadata": {},
   "source": [
    "# Data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40c2584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceData(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = \"data/processed_data\",\n",
    "        batch_size: int = 4,\n",
    "        num_workers: int = 2,\n",
    "        img_size: int = 96,\n",
    "        val_split: float = 0.2,\n",
    "        test_split: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.img_size = img_size\n",
    "        self.val_split = val_split\n",
    "        self.test_split = test_split\n",
    "\n",
    "        self.train_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.ColorJitter(\n",
    "                    brightness=0.2,\n",
    "                    contrast=0.2,\n",
    "                    saturation=0.2,\n",
    "                    hue=0.02,\n",
    "                ),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.test_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train_full = datasets.ImageFolder(\n",
    "            root=self.data_dir, transform=self.train_transform\n",
    "        )\n",
    "        val_full = datasets.ImageFolder(\n",
    "            root=self.data_dir, transform=self.test_transform\n",
    "        )\n",
    "        test_full = datasets.ImageFolder(\n",
    "            root=self.data_dir, transform=self.test_transform\n",
    "        )\n",
    "\n",
    "        targets = [y for _, y in train_full.samples]\n",
    "        n_total = len(train_full)\n",
    "        n_test = int(self.test_split * n_total)\n",
    "        n_val = int(self.val_split * n_total)\n",
    "\n",
    "        split_test = StratifiedShuffleSplit(\n",
    "            n_splits=1, test_size=n_test, random_state=SEED\n",
    "        )\n",
    "        train_val_idx, test_idx = next(split_test.split(np.zeros(n_total), targets))\n",
    "\n",
    "        train_val_targets = [targets[i] for i in train_val_idx]\n",
    "        val_size = n_val / len(train_val_idx)\n",
    "        split_val = StratifiedShuffleSplit(\n",
    "            n_splits=1, test_size=val_size, random_state=SEED\n",
    "        )\n",
    "        train_idx, val_idx = next(\n",
    "            split_val.split(np.zeros(len(train_val_idx)), train_val_targets)\n",
    "        )\n",
    "\n",
    "        train_idx = [train_val_idx[i] for i in train_idx]\n",
    "        val_idx = [train_val_idx[i] for i in val_idx]\n",
    "\n",
    "        self.train_dataset = Subset(train_full, train_idx)\n",
    "        self.val_dataset = Subset(val_full, val_idx)\n",
    "        self.test_dataset = Subset(test_full, test_idx)\n",
    "\n",
    "        print(f\"Train size: {len(self.train_dataset)}\")\n",
    "        print(f\"Val size: {len(self.val_dataset)}\")\n",
    "        print(f\"Num classes: {len(self.train_dataset.dataset.classes)}\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef049cf",
   "metadata": {},
   "source": [
    "# Lightning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06819833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceEmotionClassifier(L.LightningModule):\n",
    "    def __init__(\n",
    "        self, lr: float = 0.001, weight_decay: float = 0, betas: tuple = (0.9, 0.999)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(num_classes=7)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "        self.betas = betas\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        images, targets = batch\n",
    "        outputs = self.model(images)\n",
    "        loss = self.loss_fn(outputs, targets.long())\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets = batch\n",
    "        outputs = self.model(images)\n",
    "        loss = self.loss_fn(outputs, targets)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self.model(images)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        \n",
    "        if batch_idx == 0 and self.test_samples is None:\n",
    "            pred_labels = torch.argmax(outputs[:6], dim=1)\n",
    "            self.test_samples = {\n",
    "                'images': images[:6].cpu(),\n",
    "                'labels': labels[:6].cpu(),\n",
    "                'predictions': pred_labels.cpu()\n",
    "            }\n",
    "        \n",
    "        pred_labels = torch.argmax(outputs, dim=1)\n",
    "        acc = (pred_labels == labels).float().mean()\n",
    "        self.log_dict({'test_loss': loss, 'test_acc': acc})\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if self.test_samples is not None and self.logger:\n",
    "            fig, ax = plt.subplots(1, 6, figsize=(15, 3))\n",
    "            for i in range(6):\n",
    "                img = self.test_samples['images'][i].permute(1, 2, 0).numpy()\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                img = std * img + mean\n",
    "                img = np.clip(img, 0, 1)\n",
    "                ax[i].imshow(img)\n",
    "                ax[i].axis('off')\n",
    "                ax[i].set_title(\n",
    "                    f\"T:{self.test_samples['labels'][i].item()}\\n\"\n",
    "                    f\"P:{self.test_samples['predictions'][i].item()}\"\n",
    "                )\n",
    "            \n",
    "            self.logger.experiment.log_figure(\n",
    "                run_id=self.logger.run_id,\n",
    "                figure=fig,\n",
    "                artifact_file=\"test_predictions.png\"\n",
    "            )\n",
    "            plt.close(fig)\n",
    "            \n",
    "            self.test_samples = None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.lr,\n",
    "            betas=self.betas,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5189982",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24a1c47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 22:39:54,772] A new study created in memory with name: no-name-1128f664-d7ff-4815-825c-954573538d0d\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | ResNet           | 11.2 M | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.720    Total estimated model params size (MB)\n",
      "69        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 34847\n",
      "Val size: 9955\n",
      "Num classes: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Kajetan\\anaconda3\\envs\\MLOpsGPU\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "d:\\Users\\Kajetan\\anaconda3\\envs\\MLOpsGPU\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Kajetan\\anaconda3\\envs\\MLOpsGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", save_top_k=1)\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    mlflow_logger = MLFlowLogger(experiment_name=\"Face_Classification\")\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 0.00001, 0.01, log=True)\n",
    "    beta_l = trial.suggest_float(\"beta_l\", 0.8, 0.92, log=True)\n",
    "    beta_r = trial.suggest_float(\"beta_r\", 0.93, 0.99, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.00001, 0.1, log=True)\n",
    "\n",
    "    model = FaceEmotionClassifier(\n",
    "        lr=lr, betas=(beta_l, beta_r), weight_decay=weight_decay\n",
    "    )\n",
    "    dataset = FaceData(data_dir=\"data/processed_data\", batch_size=32)\n",
    "\n",
    "    mlflow_logger.log_hyperparams(\n",
    "        {\"lr\": lr, \"weight_decay\": weight_decay, \"beta_l\": beta_l, \"beta_r\": beta_r}\n",
    "    )\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=100,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=1,\n",
    "        logger=mlflow_logger,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, dataset)\n",
    "\n",
    "    val_loss = trainer.callback_metrics[\"val_loss\"].item()\n",
    "\n",
    "    trainer.test(model, dataset)\n",
    "\n",
    "    trial.set_user_attr(\"mlflow_run_id\", mlflow_logger.run_id)\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOpsGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
